{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##### Scikit Learn modules needed for Logistic Regression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler , StandardScaler\n",
    "\n",
    "# Plotting libraries\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes = True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('../3.Regression/data/winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of data\n",
    "# Creating 3 classes based on quality <= 4 , low; quality > 4 <= 8, medium else high\n",
    "def create_level(x):\n",
    "    # function to create levels basis wine quality\n",
    "    if x <= 5:\n",
    "        x = \"low\"\n",
    "    elif x > 5 and x < 7:\n",
    "        x = \"medium\"\n",
    "    else:\n",
    "        x = \"high\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level'] = df['quality'].apply(lambda x: create_level(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.quality.describe())\n",
    "print(df.level.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of categorical class variable to integers which will be used for feeding the model\n",
    "le = LabelEncoder()\n",
    "le_encoded = le.fit_transform(df['level'])\n",
    "#le_encoded = le.transform(le)\n",
    "print((le.classes_))\n",
    "print(le_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data visually\n",
    "# Build Correlation Matrix to\n",
    "correlation = df.iloc[:,:10].corr()\n",
    "#print(correlation)\n",
    "\n",
    "fig , ax = plt.subplots()\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(16)\n",
    "sns.heatmap(correlation,annot=True,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split Data in Training & Testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:10],le_encoded,test_size=0.20,\n",
    "                                                    random_state=21)\n",
    "\n",
    "print('Shape of Training Xs:{}'.format(x_train.shape))\n",
    "print('Shape of Test Xs:{}'.format(x_test.shape))\n",
    "print('Shape of Training y:{}'.format(y_train.shape))\n",
    "print('Shape of Test y:{}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Build Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_predicted = clf.predict(x_test)\n",
    "score=clf.score(x_test,y_test);#testing the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variableImp = pd.DataFrame({\"Feature\":df.columns[:10],\"Importance\":clf.feature_importances_})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "ax.bar(x = variableImp.Feature, height = variableImp.Importance)\n",
    "#ax.barh(x = df['Gender'], height = np.mean(df.score))\n",
    "ax.set_title('Feature Importance')\n",
    "ax.set_xlabel('Feature Names')\n",
    "ax.set_ylabel('Importance')\n",
    "ax.set_ylim(top = 0.2)\n",
    "for i, v in enumerate(variableImp.Importance):\n",
    "    ax.text(i-0.4, v + 0.01, s = np.round(v,2), color='green', fontweight='bold',fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model diagnostic\n",
    "print(score)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Predict outcome using the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on Test Data\n",
    "y_predicted_labels = le.inverse_transform(y_predicted)\n",
    "y_predicted_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = le.inverse_transform(y_test)\n",
    "true_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(true_labels, y_predicted_labels)\n",
    "np.set_printoptions(precision=2)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Normalization\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=le.classes_,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# With normalization\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= le.classes_, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphviz Windows external library:\n",
    "https://bobswift.atlassian.net/wiki/spaces/GVIZ/pages/20971549/How+to+install+Graphviz+software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Source(tree.export_graphviz(clf, out_file=None\n",
    "   , feature_names = df.columns[0:10], class_names = ['0', '1', '2'] \n",
    "   , filled = True))\n",
    "\n",
    "graph.format = 'png'\n",
    "graph.render('dtree_render',view=True)\n",
    "\n",
    "display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf,out_file='tree.dot')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem of Overfitting\n",
    "\n",
    "- Over-fitting is the phenomenon in which the learning system tightly fits the given training data so much that it would be inaccurate in predicting the outcomes of the untrained data.\n",
    "\n",
    "<img style=\"float: left;\" src = \"./img/overfitting.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting results** in decision trees that are more complex than necessary. Key reasons:\n",
    "- Tree growth went too far\n",
    "- Number of instances gets smaller as we build the tree (e.g., several leaves match a single example)\n",
    "\n",
    "**Avoid Overfitting** in decision trees:\n",
    "- Using method of Prunning (Early Stopping Method)\n",
    "    1. Stop if number of instances is less than some user-specified threshold\n",
    "    2. Stop if expanding the current node does not improve impurity measures (e.g., GAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "clf = DecisionTreeClassifier(criterion= \"entropy\",max_depth= 3)\n",
    "clf.fit(x_train, y_train)\n",
    "y_predicted = clf.predict(x_test)\n",
    "score=clf.score(x_test,y_test);#testing the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Source(tree.export_graphviz(clf, out_file=None\n",
    "   , feature_names = df.columns[0:10], class_names = ['0', '1', '2'] \n",
    "   , filled = True))\n",
    "\n",
    "graph.format = 'png'\n",
    "graph.render('dtree_render',view=True)\n",
    "\n",
    "display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf,out_file='tree.dot')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning\n",
    "\n",
    "- In contrast to __model parameters__ which are learned during training, __model hyperparameters__ are set by the data scientist ahead of training and control implementation aspects of the model. \n",
    "- The __weights learned during training__ of a linear regression model are __parameters__ while the __max heightt of a tree Decision Tree is a model hyperparameter__ because this is set by the Machine Learning Engineer. \n",
    "- __Hyperparameters__ can be thought of as __model settings__. These settings need to be tuned for each problem because the best model hyperparameters for one particular dataset will not be the best across all datasets. \n",
    "- The process of hyperparameter tuning (also called __hyperparameter optimization)__ means finding the combination of hyperparameter values for a machine learning model that performs the best - as measured on a validation dataset - for a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/train_test.png\" alt=\"Train & Test Methodology\" width=\"700\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below packages are needed for Hyper Parameter Tuning of an Algorithm in Scikit Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to check if there are any blank / empty / null values in dataframe\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = df.columns[0:10]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "# categorical_features = \n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        #('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "    'preprocessor__num__scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'classifier__criterion': [\"gini\",\"entropy\"],\n",
    "    'classifier__max_depth':[10,20,30,40]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10, iid=False,verbose = 1,n_jobs= -1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print((\"best Model from grid search: %.3f\"\n",
    "       % grid_search.score(x_test, y_test)))\n",
    "# Print your best combination of hyper parameters\n",
    "print(\"Optimum setting of hyperparameters:................\")\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(grid_search,\"DecisionTree.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
