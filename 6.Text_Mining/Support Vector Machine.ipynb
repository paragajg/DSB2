{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "<br>\n",
    "\n",
    "Support Vector Machines are __supervised learning__ models for classification and regression problems. . SVM is commonly used in classfication of text documents or image identification , in general has a good accuracy in predicting __High dimensional features.__\n",
    "\n",
    "### Use Case: Predict Rating of Side Effects of a Drug basis online comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn for feature extraction & modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Iteratively read files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# For displaying images in ipython\n",
    "from IPython.display import HTML, display\n",
    "# Plotting libraries\n",
    "from IPython.display import SVG\n",
    "#from graphviz import Source\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes = True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data files\n",
    "Drug Rating data: https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29\n",
    "\n",
    "citation: Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"drugLib_raw/drugLibTrain_raw.tsv\",sep= \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of training data set: {}\".format(df.shape))\n",
    "print(\"................................................\\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() # drop any na / null rows from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data separately\n",
    "test = pd.read_csv(\"drugLib_raw/drugLibTest_raw.tsv\",sep= \"\\t\")\n",
    "print(\"Size of training data set: {}\".format(test.shape))\n",
    "print(\"................................................\\n\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df['sideEffects'].value_counts()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data ---> Train(80%) Test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"sideEffectsReview\"], df[\"sideEffects\"],random_state = 42,\n",
    "                                                   test_size = 0.20)\n",
    "X_train.shape,X_test.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Preprocessing ---> Model Training Pipeline\n",
    "\n",
    "- Using Naive Bayes Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Pipeline for raw text transformation\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words= \"english\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Naive Bayes Classifier is {}\".format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Preprocessing ---> Model Training Pipeline\n",
    "\n",
    "### Using Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduciton: \n",
    "Rather than modeling each class, we simply find a line or curve (in two dimensions) or manifold (in multiple dimensions) that divides the classes from each other.\n",
    "\n",
    "<img src=\"images/svm.jpeg\" alt=\"svm\" style=\"width:30%\">\n",
    "\n",
    "### Goal:\n",
    "To maximize the margin between the points on either side of the so called decision line. The benefit of this process is, that after the separation, the model can easily guess the target classes (labels) for new cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear & Non Linear Data\n",
    "- Linear data or two variables are called linear if there relationship can be expressed as Y = (a0 + aiX) which is equation of line. The same data can also be divided into two regions using a line.\n",
    "<br>\n",
    "\n",
    "<img src=\"images/linear_nonlinear.png\" alt=\"lin\" style=\"width:50%\">\n",
    "- Non Linear data - has complex relationship among variables (features) and cannot be easily separated by a line as show by above figure on the right.\n",
    "\n",
    "### Kernel Trick for Non Linear data\n",
    "It is a set of mathematical transformation of exisiting features into higher dimentional feature space. This allows to define separable boundary to classify data between multiple categories.\n",
    "\n",
    "<img src=\"images/kernel.png\" alt=\"kernel\" style=\"width:50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Pipeline for raw text transformation\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words= \"english\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', svm.SVC(kernel = \"linear\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Support Vector Machine Classifier is {}\".format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test data\n",
    "y_predicted = model.predict(X_test)\n",
    "y_predicted[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "#Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Normalization\n",
    "plt.figure(figsize= (8,8))\n",
    "plot_confusion_matrix(cnf_matrix, classes= np.sort(df[\"sideEffects\"].unique()),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# With normalization\n",
    "plt.figure(figsize= (8,8))\n",
    "plot_confusion_matrix(cnf_matrix, classes= np.sort(df[\"sideEffects\"].unique())\n",
    "                      , normalize=True,title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model on Entire Data and predict Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Pipeline for raw text transformation\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words= \"english\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', svm.SVC(kernel = \"linear\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(df[\"sideEffectsReview\"],df[\"sideEffects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Naive Bayes Classifier is {}\".\n",
    "      format(model.score(test[\"sideEffectsReview\"],test[\"sideEffects\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test[\"sideEffectsReview\"])\n",
    "#Confusion Matrix\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test[\"sideEffects\"], y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Normalization\n",
    "plt.figure(figsize= (8,8))\n",
    "plot_confusion_matrix(cnf_matrix, classes= np.sort(df[\"sideEffects\"].unique()),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# With normalization\n",
    "plt.figure(figsize= (8,8))\n",
    "plot_confusion_matrix(cnf_matrix, classes= np.sort(df[\"sideEffects\"].unique())\n",
    "                      , normalize=True,title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros & Cons of SVM\n",
    "\n",
    "Below excertp from sklearn documentation on svm.\n",
    "\n",
    "__The advantages of support vector machines are:__\n",
    "\n",
    "- Effective in high dimensional spaces.\n",
    "- Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "- Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "- Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "<br>\n",
    "\n",
    "__The disadvantages of support vector machines include:__\n",
    "\n",
    "- If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "- SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross validation (see Scores and probabilities, below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading / Exploration\n",
    "\n",
    "Analytics Vidya: https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/\n",
    "\n",
    "kdnuggets: https://www.kdnuggets.com/2017/08/support-vector-machines-learning-svms-examples.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
