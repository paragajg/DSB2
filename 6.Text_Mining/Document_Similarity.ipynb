{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine\n",
    "\n",
    "## NLP: Document Similarity\n",
    "\n",
    "### Keys Concepts\n",
    "- Term Document Matrix\n",
    "- Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn for feature extraction & modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Iteratively read files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# For displaying images in ipython\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14.0, 8.7)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined function to read and store bbc data from multipe folders\n",
    "def load_data(folder_names,root_path):\n",
    "    fileNames = [path + '/' + 'bbc' +'/'+ folder + '/*.txt' for path,folder in zip([root_path]*len(folder_names),\n",
    "                                                                               folder_names )]\n",
    "    doc_list = []\n",
    "    tags = folder_names\n",
    "    for docs in fileNames:\n",
    "        #print(docs)\n",
    "        #print(type(docs))\n",
    "        doc = glob.glob(docs) # glob method iterates through the all the text documents in a folder\n",
    "        for text in doc:\n",
    "            with open(text, encoding='latin1') as f:\n",
    "                topic = docs.split('/')[8]\n",
    "\n",
    "                lines = f.readlines()\n",
    "                heading = lines[0].strip()\n",
    "                body = ' '.join([l.strip() for l in lines[1:]])\n",
    "                doc_list.append([topic, heading, body])\n",
    "        print(\"Completed loading data from folder: %s\"%topic)\n",
    "    \n",
    "    print(\"Completed Loading entire text\")\n",
    "    \n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = ['business','entertainment','politics','sport','tech']\n",
    "docs = load_data(folder_names = folder_names, root_path = os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(docs, columns=['Category', 'Heading', 'Article'])\n",
    "print(docs.head())\n",
    "print('\\nShape of data is {}\\n'.format(docs.shape))\n",
    "print(docs.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Documents Similarity</h2>\n",
    "<h3>From Documents -- DTM -- Cosine Similarity</h3>\n",
    "\n",
    "HTML(\"<table><tr><td><img src=\"images/docs_to_dtm.png\" alt=\"dtm\" style=\"width:100%\"></td><td><img src=\"images/cosine.jpg\" alt=\"Forest\" style=\"width:100%\"></td></tr></table>\")\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### Important\n",
    "The cosine similarity is the cosine of the angle between two vectors.\n",
    "- Cosine Similarity can take value between 0 to 1.\n",
    "- closer to 0 means dissimilar documents\n",
    "- closer to 1 means similar documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Documents Similar to a New document : First Step to Build Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Raw text --> Parsed Text --> Document Term Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why to Use Term Frequency Inverse Document Frequency over Term Frequency\n",
    "\n",
    "- TF*IDF is an information retrieval technique that weighs a termâ€™s frequency (TF) and its inverse document frequency (IDF). Each word or term has its respective TF and IDF score. The product of the TF and IDF scores of a term is called the TF*IDF weight of that term.\n",
    "\n",
    "__Put simply, the higher the TF*IDF score (weight), the rarer the term and vice versa.__\n",
    "\n",
    "__TFidf__ - is comprised of following two components\n",
    "- __TF: Term Frequency__, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "\n",
    "__TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).__\n",
    "\n",
    "__IDF: Inverse Document Frequency__, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "__IDF(t) = log_e(Total number of documents / Number of documents with term t in it).__\n",
    "\n",
    "__TFidf__ = TF * IDF\n",
    "\n",
    "**Important**\n",
    "Higher the TFidf , more relevent the term is to that document\n",
    "\n",
    "### Important Reading Article on TFidf\n",
    "https://www.kdnuggets.com/2018/08/wtf-tf-idf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(docs[\"Heading\"])\n",
    "print(\"Shape of tfidf matrix: {}\".format(vectors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_query = [\"World facing imminent danger across global war theaters\"]\n",
    "new_query_vector = vectorizer.transform(new_query)\n",
    "new_query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(X = vectors, Y = new_query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Index of Maximum valued similar document\n",
    "argmax = np.argmax(sim)\n",
    "print(\"Index of maximum valued similar doc: %s\"%argmax)\n",
    "print(\"Retrieved Document Header: %s\"%docs[\"Heading\"][argmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Extract Top 10 Similar Documents against the new query\n",
    "ind = np.argsort(sim,axis = 0)[::-1][:10]\n",
    "for i in ind:\n",
    "    print(docs[\"Heading\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_doc(new_query,raw_docs):\n",
    "    vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "    vectors = vectorizer.fit_transform(raw_docs[\"Article\"])\n",
    "    print(\"Shape of tfidf matrix: {}\".format(vectors.shape))\n",
    "    new_query = [new_query]\n",
    "    new_query_vector = vectorizer.transform(new_query)\n",
    "    sim = cosine_similarity(X = vectors, Y = new_query_vector)\n",
    "    ind = np.argsort(sim,axis = 0)[::-1][:10]\n",
    "    for i in ind:\n",
    "        print(docs[\"Heading\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newQuery = \"Indian political scenario\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_doc(new_query= newQuery  , raw_docs= docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
